from docx import Document
from docx.shared import Inches
import os

# Paths
doc_path = r'y:\Study\repos\adm\anomalyDetection\AnomalyDetection_Pipeline_Documentation_FINAL.docx'
img_path = r'y:\Study\repos\adm\anomalyDetection\copilot_dev\out_lightweight\diagnostics_plots\pair_account_behavior.png'

# Create document
doc = Document()
doc.add_heading('Anomaly Detection Pipeline Documentation', 0)

doc.add_heading('Overview', level=1)
doc.add_paragraph(
    "This project implements a robust, production-ready anomaly detection pipeline for weekly count data, supporting multiple (target_type, insight_type) pairs and keys. The pipeline is designed to handle different seasonality, trends, and abrupt changes in the data, and provides:\n"
    "- Model selection (Negative Binomial with Fourier terms)\n"
    "- Change point detection (ruptures)\n"
    "- Robust fallback\n"
    "- Diagnostics and visualization"
)

doc.add_heading('Data Structure', level=1)
doc.add_paragraph(
    "Input CSV: Must contain at least the following columns:\n"
    "- insight_date_time (datetime)\n"
    "- target_type (categorical)\n"
    "- insight_type (categorical)\n"
    "- target_key (categorical)"
)

doc.add_heading('Pipeline Steps', level=1)
doc.add_paragraph(
    "1. Data Aggregation\n"
    "   - Aggregates raw data to weekly counts for each (target_type, insight_type, target_key).\n"
    "   - Fills missing weeks with zero counts.\n"
    "2. Model Fitting & Selection\n"
    "   - For each (target_type, insight_type) pair and key:\n"
    "     - Fits Negative Binomial (NB2) regression models with different numbers of Fourier terms (seasonality).\n"
    "     - Selects the best model using AIC.\n"
    "     - If model fitting fails, uses a robust rolling window fallback.\n"
    "3. Change Point Detection\n"
    "   - Uses the ruptures library (Pelt algorithm, model='l2', log1p transform) to detect change points in each time series.\n"
    "   - If a change point is found, splits the series and fits separate models to each segment.\n"
    "4. Anomaly Detection\n"
    "   - Calculates prediction intervals using the NB2 model.\n"
    "   - Flags anomalies where observed counts fall outside the prediction interval.\n"
    "5. Diagnostics & Visualization\n"
    "   - Outputs diagnostics (AIC, fallback usage, change points) for each segment to a CSV.\n"
    "   - Generates plots for each series, showing:\n"
    "     - Actual counts\n"
    "     - Predicted mean\n"
    "     - Prediction intervals\n"
    "     - Anomalies (red dots)\n"
    "     - Change points (purple vertical lines)\n"
    "   - Plots are saved in diagnostics_plots/."
)

doc.add_heading('Output Files', level=1)
doc.add_paragraph(
    "- light_nb_flags_by_key_weekly.csv: Anomaly flags for each key.\n"
    "- light_nb_flags_by_pair_weekly.csv: Anomaly flags for each pair.\n"
    "- diagnostics.csv: Model diagnostics for each segment.\n"
    "- diagnostics_plots/: Plots for each pair and key."
)

doc.add_heading('Example Visualization', level=1)
doc.add_paragraph("Below is an actual example plot generated by the pipeline:")
if os.path.exists(img_path):
    doc.add_picture(img_path, width=Inches(5))
doc.add_paragraph(
    "Explanation:\n"
    "- Blue line: Actual weekly counts\n"
    "- Dashed line: Model-predicted mean\n"
    "- Gray band: Prediction interval\n"
    "- Red dots: Detected anomalies\n"
    "- Purple lines: Detected change points"
)

doc.add_heading('Code Structure', level=1)
doc.add_paragraph(
    "lightweight_nb_anomaly.py: Main script implementing the pipeline.\n"
    "  - Key functions: ensure_weekly_counts, build_design, fit_nb2, predict_pi, robust_fallback, detect_change_points, plot_series, main\n"
    "run_lightweight.py: Runner script to execute the pipeline with the correct input/output paths."
)

doc.add_heading('Requirements', level=1)
doc.add_paragraph(
    "Python 3.7+\n"
    "pandas\n"
    "numpy\n"
    "statsmodels\n"
    "ruptures\n"
    "matplotlib\n"
    "Install with:\n"
    "    pip install pandas numpy statsmodels ruptures matplotlib"
)

doc.add_heading('Usage', level=1)
doc.add_paragraph(
    "1. Place your input CSV in the correct location.\n"
    "2. Update run_lightweight.py if needed.\n"
    "3. Run:\n"
    "    python run_lightweight.py\n"
    "4. Review outputs in the out_lightweight directory."
)

doc.add_heading('Notes', level=1)
doc.add_paragraph(
    "- The pipeline is robust to missing data, overdispersion, and abrupt changes.\n"
    "- Diagnostics and plots help validate model quality and anomaly detection.\n"
    "- You can tune the change point penalty (pen in detect_change_points) and model complexity (fourier_K) as needed."
)

doc.add_heading('Contact', level=1)
doc.add_paragraph("For further customization or support, contact your data science team.")

doc.add_heading('Gen AI Prompt for Copilot or ChatGPT', level=1)
doc.add_paragraph(
    "If you want to re-create this pipeline on any new data, use this prompt:\n\n"
    "I have weekly count data in CSV format, with columns like `target_type`, `insight_type`, `target_key`, `insight_date_time`, and I want to detect anomalies for each (target_type, insight_type) pair and key.\n\n"
    "Please develop a robust Python pipeline that:\n"
    "- Aggregates the data to weekly counts for each (target_type, insight_type, target_key).\n"
    "- For each (target_type, insight_type) pair and key:\n"
    "    - Fits multiple Negative Binomial (NB2) models with different numbers of Fourier terms (for seasonality) and selects the best model using AIC.\n"
    "    - Detects change points in the time series using the `ruptures` library (with a log1p transform and `model='l2'`), and if a change point is found, fits separate models to each segment.\n"
    "    - Uses a robust rolling window fallback if model fitting fails.\n"
    "    - Calculates prediction intervals using the NB2 model and flags anomalies outside the interval.\n"
    "    - Collects diagnostics (AIC, fallback usage, change points) for each segment and saves them to a CSV.\n"
    "    - Generates and saves plots for each series, showing actuals, predictions, intervals, anomalies, and change points.\n"
    "- Outputs:\n"
    "    - Anomaly flags for each key and pair as CSVs.\n"
    "    - Diagnostics CSV.\n"
    "    - Plots for each series in a diagnostics folder.\n"
    "- Use only open-source Python libraries (pandas, numpy, statsmodels, ruptures, matplotlib).\n"
    "- The code should be robust, modular, and ready to run on new data with similar structure.\n\n"
    "Please provide the full code, including requirements, and ensure it is thoroughly tested and handles edge cases."
)

doc.save(doc_path)
print(f"Documentation with embedded plot saved to: {doc_path}")
